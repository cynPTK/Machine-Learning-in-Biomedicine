---
title: "PS3"
author: "Cynthia Nguyen"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
# Required Libraries
library(ggplot2)

# Function to load genotype file and convert it to a matrix
load_geno_file <- function(filepath) {
  data <- readLines(filepath)
  geno_matrix <- t(sapply(data, function(x) as.numeric(strsplit(x, "")[[1]])))
  return(geno_matrix)
}

# Initialize parameters for the model
initialize_parameters <- function(K, num_sps) {
  # Initialize frequencies with random values between 0.01 and 0.99 to avoid extreme values
  freq <- matrix(runif(num_sps * K, 0.01, 0.99), nrow = num_sps, ncol = K)
  # Initialize mixing proportions (pi) using exponential distribution and normalize
  pi <- rexp(K)
  pi <- pi / sum(pi)
  return(list(pi = pi, freq = freq))
}

# E-step: Compute responsibilities (posterior probabilities)
e_step <- function(geno, pi, freq, K) {
  num_individuals <- ncol(geno)
  log_likelihood <- matrix(0, nrow = num_individuals, ncol = K)
  
  # Ensure freq values are clipped to prevent issues with log(0) or log(1)
  freq <- pmax(pmin(freq, 1 - 1e-10), 1e-10)  # Clip to prevent log(0)
  
  for (k in 1:K) {
    # Calculate the log-probabilities to avoid numerical underflow
    log_prob <- rowSums(geno * log(freq[, k]) + (1 - geno) * log(1 - freq[, k]))
    log_likelihood[, k] <- log_prob[1] + log(pi[k])
  }
  
  max_log_likelihood <- apply(log_likelihood, 1, max)
  log_sum_exp <- max_log_likelihood + log(rowSums(exp(log_likelihood - max_log_likelihood)))
  
  log_responsibilities <- log_likelihood - log_sum_exp
  responsibilities <- exp(log_responsibilities)
  
  return(responsibilities)
}

# M-Step: Update the parameters (pi and freq)
m_step <- function(geno, responsibilities, K) {
  Nk <- colSums(responsibilities) + 1e-10  # Add small value to avoid divide by zero
  pi <- Nk / sum(Nk)  # Update pi (mixing proportions)
  freq <- sweep(geno %*% responsibilities, 2, Nk, FUN = "/")  # Update freq (feature probabilities)
  
  return(list(pi = pi, freq = freq))
}

# Log-likelihood computation
compute_log_likelihood <- function(geno, pi, freq, K) {
  num_individuals <- ncol(geno)
  log_likelihood <- matrix(0, nrow = num_individuals, ncol = K)
  
  freq <- pmax(pmin(freq, 1 - 1e-10), 1e-10)  # Clip to prevent log(0)
  
  for (k in 1:K) {
    log_prob <- rowSums(geno * log(freq[, k]) + (1 - geno) * log(1 - freq[, k]))
    print(dim(log_prob))
    log_likelihood[, k] <- log_prob[1] + log(pi[k])
  }
  
  max_log_likelihood <- apply(log_likelihood, 1, max)
  log_sum_exp <- max_log_likelihood + log(rowSums(exp(log_likelihood - max_log_likelihood)))
  
  return(sum(log_sum_exp))
}

# EM Algorithm: Run the Expectation-Maximization
em_algorithm <- function(geno, K, max_iter = 100, tol = 1e-8) {
  params <- initialize_parameters(K, nrow(geno))
  pi <- params$pi
  freq <- params$freq
  
  log_likelihoods <- numeric(max_iter)
  
  for (i in 1:max_iter) {
    # E-step: Compute responsibilities
    responsibilities <- e_step(geno, pi, freq, K)
    
    # M-step: Update parameters
    params <- m_step(geno, responsibilities, K)
    pi <- params$pi
    freq <- params$freq
    
    # Compute log-likelihood
    log_likelihood <- compute_log_likelihood(geno, pi, freq, K)
    log_likelihoods[i] <- log_likelihood
    
    # Check for convergence (if log-likelihood change is below tolerance)
    if (i > 1 && abs(log_likelihoods[i] - log_likelihoods[i-1]) < tol) {
      print("Converges")
      break
    }
  }
  
  return(list(pi = pi, freq = freq, log_likelihoods = log_likelihoods, responsibilities = responsibilities))
}

# Running EM Algorithm with 3 random restarts
em_algorithm_with_restarts <- function(geno, K, max_iter = 100, tol = 1e-8, restarts = 3) {
  best_log_likelihood <- -Inf
  best_params <- NULL
  best_log_likelihoods <- NULL
  
  for (restart in 1:restarts) {
    cat("Restart", restart, "\n")
    
    result <- em_algorithm(geno, K, max_iter, tol)
    
    if (result$log_likelihoods[length(result$log_likelihoods)] > best_log_likelihood) {
      best_log_likelihood <- result$log_likelihoods[length(result$log_likelihoods)]
      best_params <- list(pi = result$pi, freq = result$freq)
      best_log_likelihoods <- result$log_likelihoods
    }
  }
  
  return(list(best_params = best_params, best_log_likelihoods = best_log_likelihoods))
}
```


```{r}
# Example usage
geno_file <- "C:/Users/WINDOWS/Desktop/DSB 205/data/Q2/mixture1.geno"
geno <- load_geno_file(geno_file)
```


```{r}
K <- 2  # Number of clusters
result <- em_algorithm_with_restarts(geno, K, max_iter = 100, tol = 1e-8, restarts = 3)

# best_params will hold the best pi and freq
# best_log_likelihoods will hold the log-likelihoods for the best restart

# Plotting log-likelihoods
ggplot(data.frame(Iteration = 1:length(result$best_log_likelihoods), LogLikelihood = result$best_log_likelihoods), aes(x = Iteration, y = LogLikelihood)) +
  geom_line() +
  labs(title = "Log-Likelihoods of the Best Restart", x = "Iterations", y = "Log-Likelihood") +
  theme_minimal()

```

```{r}
# MLE of π for dataset 1
result$best_params$pi

max(result$best_log_likelihoods)
```


```{r}
# True population labels (from mixture1.ganc file)
true_labels <- scan('C:/Users/WINDOWS/Desktop/DSB 205/data/Q2/mixture1.ganc', what = integer())  # Replace with actual file path

# MAP estimate of population labels
inferred_labels <- ifelse(results$best_params$freq[, 2] > results$best_params$freq[, 1], 0, 1)

# Calculate accuracy
accuracy <- sum(inferred_labels == true_labels) / n
accuracy
```

```{r}
# Run EM with 3 random restarts and report log-likelihood and accuracy
log_likelihoods <- numeric(3)
accuracies <- numeric(3)

for (i in 1:3) {
  result <- EM_algorithm(dataset1)
  log_likelihoods[i] <- result$log_likelihoods[length(result$log_likelihoods)]
  inferred_labels <- apply(result$r, 1, which.max)
  accuracies[i] <- sum(inferred_labels == true_labels) / n
}

log_likelihoods
accuracies
```

```{r}
# Vary the number of SNPs
snp_counts <- c(10, 100, 1000, 5000)
accuracies_snp <- numeric(length(snp_counts))

for (i in 1:length(snp_counts)) {
  dataset_subset <- dataset1[, 1:snp_counts[i]]
  result <- EM_algorithm(dataset_subset)
  inferred_labels <- apply(result$r, 1, which.max)
  accuracies_snp[i] <- sum(inferred_labels == true_labels) / n
}

# Plot accuracy vs number of SNPs
plot(snp_counts, accuracies_snp, type = 'o', xlab = 'Number of SNPs', ylab = 'Accuracy', 
     main = 'Accuracy vs. Number of SNPs')
```

```{r}
# Assuming dataset2 is available
dataset2 <- matrix(rnorm(n * m), ncol = m)  # Replace with actual dataset

# Run EM on dataset2
result2 <- EM_algorithm(dataset2)

# MLE of π for dataset 2
result2$pi
```

```{r}
K_values <- 1:4
log_likelihood_K <- numeric(length(K_values))

for (k in K_values) {
  result <- EM_algorithm(dataset2)
  log_likelihood_K[k] <- result$log_likelihoods[length(result$log_likelihoods)]
}

# Plot log-likelihood as a function of K
plot(K_values, log_likelihood_K, type = 'b', xlab = 'Number of Components (K)', 
     ylab = 'Log Likelihood', main = 'Log Likelihood vs. K for Dataset 2')
```

```{r}
set.seed(0)  # Set the seed for reproducibility
pca_result <- prcomp(genotype_data, scale = TRUE)  # Perform PCA
pca_scores <- pca_result$x  # Extract the PCA scores

```

```{r}
library('tidyverse')
data = read_tsv('C:/Users/WINDOWS/Desktop/DSB 205/data/Q3/q3.data')
snps = data %>% select(starts_with('rs'))
```

```{r}
pca_df <- prcomp(snps, scale = TRUE)
pca_scores <- data.frame(pca_df$x)  # Extract the PCA scores
population <-data$population
```

```{r}
library(ggplot2)

ggplot(data = pca_scores) + 
  geom_point(aes(x = PC1, y = PC2, color = population)) + 
  scale_color_brewer(palette ='Set1') +
  theme_bw() 
```


```{r}
# Perform k-means clustering with 4 clusters and 5 initializations
kmeans_result <- kmeans(snps, centers = 4, nstart = 5)
kmeans_clusters <- kmeans_result$cluster  # Extract the cluster assignments
```

```{r}
# Get the size of each cluster
cluster_sizes <- table(kmeans_clusters)

# Order clusters by size (largest to smallest)
cluster_order <- order(cluster_sizes, decreasing = TRUE)

# Rename clusters (the largest cluster becomes Cluster1, the smallest becomes Cluster4)
cluster_rename <- setNames(seq_along(cluster_order), names(cluster_sizes[cluster_order]))
kmeans_clusters_renamed <- factor(kmeans_clusters, levels = cluster_order, labels = paste("Cluster", cluster_rename))

# Add renamed clusters to PCA scores (assuming PCA result stored in pca_scores)
pca_scores$Cluster <- kmeans_clusters_renamed

```

```{r}
ggplot(pca_scores, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point() +
  labs(title = "PCA of SNP Data with K-means Clusters", x = "PC1", y = "PC2") + 
	  scale_color_brewer(palette ='Set1') +
	  theme_bw() 
```


```{r}
cluster_rename <- c("EUR", "ASN", "AFR", "AMR")
names(cluster_rename) <- names(cluster_sizes[cluster_order])

# Reassign the cluster labels
kmeans_clusters_renamed <- factor(kmeans_clusters, levels = cluster_order, labels = cluster_rename)

pca_scores$Cluster <- kmeans_clusters_renamed

ggplot(pca_scores, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point() +
  labs(title = "PCA of SNP Data with K-means Clusters", x = "PC1", y = "PC2")+ 
	  scale_color_brewer(palette ='Set1') +
	  theme_bw() 

# Assuming true population labels are stored in a vector 'population_labels'
agreement <- sum(kmeans_clusters_renamed == population) / length(population)
agreement
```






















